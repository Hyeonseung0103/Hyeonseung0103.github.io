---
layout: single
title: "RCNN : Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation 논문 요약"
toc: true
toc_sticky: true
category: Detection
---

# Abstract
지난 몇년동안(2013) PASCAL VOC dataset에 관해 객체 탐지의 성능 향상이 더디다. 대화마다 best model은 일반적으로 여러개의 저수준 피처와 고수준의 context를 결합한 복잡한 앙상블 구조이다. 
본 연구에서는 단순한 탐지 알고리즘으로 VOC 2012에서 mAP 53.3%를 달성하며 지난 대회 대비 30% 이상 성능을 향상시킨 방법에 대해 제안한다. 본 논문의 두가지 키포인트는 첫째, bottom-up region proposal에 
high capacity CNN을 적용해서 localize와 segment objects를 할 수 있는 것과 둘째, 훈련 데이터가 부족한 경우 사전 학습 모델을 fine tuning하여 성능을 크게 높였다는 것이다. Region
proposal이 CNN과 결합되었기 떄문에 R-CNN이라 부르고, 최근 개발된 sliding window 개념을 활용한 CNN 아키텍처인 OverFeat과 비교했을 때 ILSVRC2013 탐지부문에서 큰 격차로 우승했다.
<br><br>

# Details
## 도입부
- 지난 10년간 visual recogniton task에서 SIFT, HOG와 같은 방법을 기반으로 많은 진전이 있었다. 하지만, 2010 ~ 2012년까지 일반적인 객체 탐지 부문인 PASCAL VOC에서는 발전이 더디었다.
- CNN이 ImageNet 데이터뿐만 아니라 PASCAL VOC에도 적합할까?
- 본 논문에서는 deep network로 객체를 localize하고, 적은 데이터만 가지고도 high-capacity model을 훈련하는 두 가지 문제에 집중하며 CNN이 HOG에 비해 PASCAL VOC의 객체 탐지 성능을 크게 향상시켰다는 것을 보여주는 첫번째 논문이다.
- 이미지 분류와는 달리 객체 탐지에서는 localization이라는 회귀 문제가 있기때문에 기존의 CNN 방식으로는 성능이 그리 좋지 않았고, sliding window 개념을 사용하여 공간 정보를 잘 유지하려고했지만,
layer가 깊어질수록 입력이미지에 대한 receptive field가 커져서 정밀한 localization을 수행하기에는 어려움이 따른다.
- 이를 해결하기 위해 약 2000개의 독립적인 RoI(Region of Interest, 물체가 존재할 것이라고 판단하는 영역)를 제시하고 각 영역에 대해 CNN으로 고정된 길이의 특징으로 추출한 다음
추출된 결과를 SVM을 통해 클래스로 분류하는 방법을 사용한다.
- 객체 탐지 시 데이터가 충분하지 않아서 사전학습 된 모델을 fine tuning하여 성능을 높였고 8%나 성능을 향상시켰다.

<br><br>

## Object detection with R-CNN
본 연구의 object detection은 크게 3가지 모듈로 이루어져있다. 첫째는 region proposal을 생성하는 모듈로 객체가 있을 것이라고 판단되는 region의 후보를 추려내는 모듈이다. 둘째는,
CNN을 통해 추려낸 모듈 중에 고정된 길이의 특징 벡터를 추출하는 모듈이다. 셋째는, SVM을 통해 분류를 수행하는 모듈이다.

### 1. Module design
**Region proposals**
- 최근 많은 논문들이 cateogy-independent region proposals를 생성하는 방법을 제공하고 있다.
- R-CNN은 selective search(이미지의 얼룩진 부분을 유사한 category로 판단하여 하나의 영역으로 제안하는 알고리즘. 그 후 bottom-up 방식으로 비슷한 영역을 합쳐서 결과적으로 약 2000개의 region proposal을 만듬)를 기반으로 region proposals을 수행한다.

**Featrue extraction**
- AlexNet 연구를 기반으로 selective search 제안된 영역에서 4096의 차원을 갖는 특징을 추출한다. 5개의 합성곱과 2개의 전결합층으로 이루어져있다.
- 제안된 영역은 CNN의 구성에 맞게 크기가 조정되어야 하므로(227 x 227) bonding box의 크기나 가로 세로 비율에 상관없이 warping(crop, 왜곡 등의 이미지 변형)시킨다.
- 경계에 bounding box가 있으면 약간 확대시키고 padding 16을 적용한다.

### 2. Test-time detection
Test 시에는 제안된 영역마다 특징이 추출되면 해당 특징을 SVM에 입력해 각 영역마다의 점수를 매긴다. 최종 예측을 위해서는 하나의 객체당 하나의 bonding box만 남겨져야하는데 NMS(Non-Maximum Suppression)
방법을 통해 score가 threshold보다 낮은 박스를 모두 제거시키고, 만약 threshold보다 높더라도 정답 bounbding box와 가장 중첩된 (IoU가 가장 높은) box를 제외하고는 모든 box를 제거시켜
각각의 객체마다 하나의 bounding box만 남도록 한다.

**Run-time analysis**
- 모든 CNN 파라미터가 모든 categories에 대해 공유되고, 특징 벡터는 다른 여러가지 접근 방법들에 비해 저차원이라는 2가지 특징이 detection을 효과적으로 만들었다.
- Class별로 이루어지는 유일한 계산은 특징 벡터와 SVM 가중치 사이의 연산과 NMS이다. Feature matrix는 일반적으로 2000 x 4096이고, SVM 가중치 행렬은 4096 x N(N은 클래스수)이다.
- 고차원의 특징을 학습할 때보다 훨씬 더 적은 시간과 연산시간을 가진 효과적인 네트워크를 구축했다. 더 좋은 성능을 가지면서 다른 모델에 비해 예측 시간이 빠른 모델이다.

### 3. Training
**Supervised pre-training & Domain-specific fine-tuning**
- Bonding box는 없지만 ILSVRC 2012 classification datsets을 가지고 CNN 모델을 pre-training 시켰다.
- Dectection이라는 새로운 tasks를 수행하기위해는 SGD를 사용해 CNN 파라미터를 학습 시켰고 데이터는 warped region proposals만 사용했다.
- IoU의 threshold는 bonding box의 IoU가 0.5이상을 positive, 미만을 negative로 했고 pre-trained 모델의 1/10인 0.001을 SGD의 학습률로 사용했다. 각 SGD iteration에는
128(32개의 전경 class, 96개의 배경 class)개의 mini batch가 사용되었다.

**Object category classifier**
- 자동차를 탐지하는 task라면 자동차를 positive, 그 외의 배경을 negative로 취급한다. 하지만, 만약 자동차가 일부 배경과 겹쳐져있다면 어떻게 할까?
- 본 연구에서는 이와 같은 overlap 문제를 해결하기 위해 regions 중 IoU overlab threshold가 0.3이상이면 해당 box에 객체가 있다고 판단한다. 0.3이라는 수치는 validation set에서 grid search(0.1, ..., 0.5)를 통해 도출했다.
- 특징이 추출되면 각 클래스마다 하나의 linear SVM을 사용해서 정답과 예측결과를 비교하며 모델을 최적화시키는데 모든 클래스를 한번에 처리하지 않고, 각각의 클래스마다 독립적으로 SVM을 최적화시키기때문에 많은 시간이 소요된다.
- 이를 해결하기위해 수렴이 빠르고 모든 이미지를 한번 처리하고 나면 mAP가 증가하지 않는 standard hard negative mining methods를 사용한다.


### 4. Results on PASCAL VOC 2010-12 & ILSVRC2013 detection
- 다른 여러 모델들과 비교했을 때 본 연구의 SVM은 VOC 2010에서 53.7% mAP를 ,2011/12에서 53.3% mAP를 달성하며 가장 좋은 성능을 냈다.
- ILSVRC2013 detection에서는 OverFeat의 24.3%의 mAP보다 훨씬 더 뛰어난 31.4%의 mAP를 기록하며 이전 대회의 기록보다 더 좋은 성능을 냈다.

<br><br>

## Visualization, ablation, and modes of error
### 1. Visualizaing learned fatures
- 첫번째 레이어는 선, 점과 같이 저수준의 특징을 학습하기때문에 직관적인 시각화가 가능한데 그 후의 레이어들은 복잡한 특징을 학습해서 시각화하기가 어렵다.
- 따라서, 각층마다 어떻게 학습이 이루어지는지 파악하기 위해 non-parametric(비모수적 방법. 분석에 대해 사전가정을 포함하지 않는, 즉, 파라미터가 사전에 정해져있지 않은 통계적 기법. 데이터에서 패턴이나
관계를 추정할 때 사용되고 데이터의 순위, 순서, 통계량 등 데이터를 기반으로 분석을 진행)방법을 사용한다.
- 특징 feature(unit)을 하나의 detector로 취급하고 여러 region proposals에 대해 activation을 적용해서 activation이 높은 순부터 낮은 순까지 정렬한 후 NMS를 적용하고 top score를 시각화한다.
이 방법은 activation이 높은, 즉, top ranking에 위치한 unit은 내가 물체를 가지고 있다는 자신감을 대변한다는 idea다.
- layer pool5의 units을 시각화한 결과, network는 몇몇 클래스의 feature와, 모양, 텍스처, 색상 등알 결합하여 학습한다는 것을 알 수 있다. 이후, fully connected layer는 이 정보들을 기반으로 더 높은 수준의 특징을 가지고
학습을 진행한다.

### 2. Ablation studies
**Performance layer-by-layer, without fine-tuning**
- 어떤 레이어가 중요한지 파악하기 위해 CNN의 마지막 3개 레이어를 살펴봤다(Layer pool5는 생략).
- Layer fc6은 4096 x 9216에 pool5의 피처맵을 곱하고, Layer fc7은 4096 x 4096에 fc6의 피처맵을 곱한다.
- fine tuning을 사용하지 않았을 때 Layer fc6과 fc7이 없을 때 성능이 더 좋았다. 전결합층으로 인한 많은 연산량이 오히려 성능을 하락시켰다.
- CNN은 전결합층보다 convolution layer가 중요하다.

**Performance layer-by-layer, with fine-tuning**
- Fine tuning 결과 성능이 8%나 상승했는데 이를 통해 fine tuning의 효과가 pool5보다 fc6,7에서 더 컸다.
- 이로인해 pool5까지는 ImageNet을 학습하여 일반적이고, fine tuning 한 분류기에서 해당 도메인에 특화되고 non-linear한 분류기가 구축된 것을 알 수 있다.

**Comparison to recent feature learning methods**
- DPM에서 사용한 DPM ST와 DPM HSC 이 두 가지 feature learning methods를 RCNN에 적용하여 DPM과 결과를 비교했다.
- Feature learning methods를 사용한 RCNN은 최신 DPM과 비교했을 때보다 더 좋은 성능을 가졌다.

### 3. Network architectures
- 본 연구에서 구현된 대부분의 아키텍처는 AlexNet을 참고했지만 어떤 아키텍처를 쓰느냐에 따라 탐지 성능이 크게 달라진다는 것을 알게되었다.
- O-Net(OxfordNet, VGG16)을 pre-trained 모델로 사용하고, 같은 환경에서 pre-trained 시킨 T-Net(TorontoNet)과 비교해본 결과 O-Net의 성능이 더 뛰어났다.
- 하지만, O-Net은 T-Net에 비해 7배 더 큰 연산 시간을 가진다는 것이 한계로 드러났다.

### 4. Detection error analysis & Bonding-box regression
- Hoiem의 Detection analysis를 기반으로 본 모델의 에러 모드와, fine-tuning이 에러 모드를 어떻게 바꾸는지, 에러 type이 DPM과 어떻게 다른지 비교했다.
- Error anlysis를 기반으로 localization error를 줄이는 방법을 적용했다. DPM의 bounding-box regression에 영감을 받아, selective search region proposal에 대한
pool5의 features가 주어지면 새로운 detection window를 예측하는 linear regression 모델을 학습시킨다.
- 이 간단한 접근 방식이 mislocaliztion을 줄여서 mAP를 3~4 points 올리는 중요한 방법이 되었다.

## The ILSVRC2013 detection dataset

## Conclusion
- 

# 개인적인 생각
- 

<br><br>

# 구현
RCNN을 pytorch로 구현해보자.

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
```

```python

```

```python


```

```python

```

```python

```

```python

```

# 이미지 출처
- [Rich feature hierarchies for accurate object detection and semantic segmentation](https://arxiv.org/pdf/1311.2524.pdf)
