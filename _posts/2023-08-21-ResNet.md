---
layout: single
title: "ResNet(Deep Residual Learning for Image Recognition)논문 요약"
toc: true
toc_sticky: true
category: CNN
---

# Abstract
신경망의 깊이가 깊어질수록 학습이 더 어려워진다. 본 논문에서는 레이어를 잔차함수로 변환하는 residual learning framework를 적용하여 이전의 모델들보다 더 깊은 신경망일지라도 학습이 잘 되게 했다.  
깊이가 최대 152인 네투워크이지만 VGG모델보다 8배 깊지만 더 낮은 복잡성을 가지고 ImageNet 데이터셋에서 ILSVRC 2015 Classification 부문에서 1위를 차지했다.

<br><br>

# Details
## 도입부 & 관련 논문
- 여러 연구를 통해 깊이가 깊어질수록 딥러닝 모델의 성능이 더 좋아진다는 것을 알 수 있었다.
- 깊이의 중요성이 부각되면서 더 좋은 네트워크를 구축하기 위해 단순히 깊이만 증가시키면 되냐는 질문을 할 수 있는데 깊이가 깊어질수록 vanishing/exploding gradients 문제가 발생할 수 있고,
가중치 초기화나 배치 정규화 등을 통해 이 문제를 해결할 수 있었다.

<br><br>

<div align="center">
  <p>
  <img width="490" alt="image" src="https://github.com/Hyeonseung0103/Hyeonseung0103.github.io/assets/97672187/0d9eecf7-d684-43ee-a10f-f2657017fabe">
  </p>
</div>

<br><br>

- 하지만, 깊이가 깊어질수록 위의 그래프처럼 정확도가 포화상태가 되는 현상도 발생할 수 있는데 과대적합과는 별개로 깊이때문에 training error가 크게 발생할 수 있다.
- 얕은 모델에 레이어를 더해 보다 깊은 모델을 만들었으면 이 모델은 기존의 얕은 모델보다 더 높은 정확도가 되어야하는데 그렇지 못한 경우가 생겼다.
- 

<br><br>

## Deep Residual Learning
### 1. Residual Learning

### 2. Identity Mapping by Shortcuts

### 3. Network Architectures

### 5. Implementation

<br><br>

<div align="center">
  <p>
  <img width="490" alt="image" src="https://github.com/Hyeonseung0103/Hyeonseung0103.github.io/assets/97672187/0d9eecf7-d684-43ee-a10f-f2657017fabe">
  </p>
</div>

<br><br>



<br><br>

## Experiments
### 1. ImageNet Classification



### 2. CIFAR-10 and Analysis

### 3. Object Detection on PASCAL and MS COCO


### 3. 훈련 및 성능
**훈련 방법**


**성능**


<br><br>


## 결론


<br><br>

# 개인적인 생각
- 

<br><br>

# 구현
ResNet을 pytorch로 구현해보자([참고]([https://github.com/pytorch/vision/blob/6db1569c89094cf23f3bc41f79275c45e9fcb3f3/torchvision/models/googlenet.py](https://github.com/pytorch/vision/blob/6db1569c89094cf23f3bc41f79275c45e9fcb3f3/torchvision/models/resnet.py)https://github.com/pytorch/vision/blob/6db1569c89094cf23f3bc41f79275c45e9fcb3f3/torchvision/models/resnet.py).

```python

```


```python


```

# 이미지 출처
- 
