---
layout: single
title: "ResNet(Deep Residual Learning for Image Recognition)논문 요약"
toc: true
toc_sticky: true
category: CNN
---

# Abstract
신경망의 깊이가 깊어질수록 학습이 더 어려워진다. 본 논문에서는 레이어를 잔차함수로 변환하는 residual learning framework를 적용하여 이전의 모델들보다 더 깊은 신경망일지라도 학습이 잘 되게 했다.  
깊이가 최대 152인 네투워크이지만 VGG모델보다 8배 깊지만 더 낮은 복잡성을 가지고 ImageNet 데이터셋에서 ILSVRC 2015 Classification 부문에서 1위를 차지했다.

<br><br>

# Details
## 도입부 & 관련 논문
- 여러 연구를 통해 깊이가 깊어질수록 딥러닝 모델의 성능이 더 좋아진다는 것을 알 수 있었다.
- 깊이의 중요성이 부각되면서 더 좋은 네트워크를 구축하기 위해 단순히 깊이만 증가시키면 되냐는 질문을 할 수 있는데 깊이가 깊어질수록 vanishing/exploding gradients 문제가 발생할 수 있고,
가중치 초기화나 배치 정규화 등을 통해 이 문제를 해결할 수 있었다.

<br><br>

<div align="center">
  <p>
  <img width="490" alt="image" src="https://github.com/Hyeonseung0103/Hyeonseung0103.github.io/assets/97672187/0d9eecf7-d684-43ee-a10f-f2657017fabe">
  </p>
</div>

<br><br>

- 하지만, 깊이가 깊어질수록 위의 그래프처럼 정확도가 포화상태가 되는 현상도 발생할 수 있는데 과대적합과는 별개로 깊이때문에 training error가 크게 발생할 수 있다.
- 얕은 모델에 레이어를 더해 보다 깊은 모델을 만들었으면 이 모델은 기존의 얕은 모델보다 더 높은 정확도가 되어야하는데 그렇지 못한 경우가 생긴다. 본 논문은 이러한 문제를 해결하기 위해 residual mapping을 적용한다.
- residual mapping은 입력으로부터 출력을 예측하는 것이 아니라 입력이 출력이 되기 위한 가중치 layer를 예측하는 방법으로 아래와 같이 표현할 수 있다.

<br><br>

<div align="center">
  <p>
  <img width="288" alt="image" src="https://github.com/Hyeonseung0103/Hyeonseung0103.github.io/assets/97672187/55587f09-54f1-44b9-819f-9c598652d3fc">

  </p>
</div>

<br><br>

- 예측하고자 하는 output인 H(x), input을 x, 가중치 layer를 F(x)라고 하면, H(x) = F(x) + x라고 할 수 있고, output인 H(x)를 도출하기 위해 F(x)를 학습하는 것이다. F(x) = H(x) - x 라고 정의할 수 있고 이는 결국 output과 input의 차이를 학습하는 것이기때문에 residual mapping이라고 표현한다.
- 극단적으로 identity mapping이 최적이라고 할 때 여러 개의 비선형 레이어를 쌓아 identity mapping에 fit하게 만드는 것보다 잔차를 0으로 만드는 방법이 더 쉬운 방법이다.
- F(x)에 x를 더하는 방법을 shortcut connections이라고 표현하고(skip connections이라고 부르기도 함) x를 더해줌으로써 input과 output의 크기가 같아지기때문에 identity mapping의 효과도 적용된다. 복잡한 연산이 사용되지 않고 단순히 가중치 레이어에 입력값을 더하는 해이기때문에 시간 복잡도나 파라미터수가 크게 요구되지 않아서 결과적으로 깊이가 깊어지더라도 기존의 네트워크들보다 적은 연산으로 성능을 올릴 수 있는 방법이 됐다.
- VLAD 논문에서 이미 잔차 벡터를 인코딩한 vector quantization 방법이 효과적이라는 연구가 있었고, GoogLeNet에서는 기울기 소실/폭발 문제를 해결하기위해 auxiliary classifier를 활용해서 중간층에서도 출력값을 만들었다. 또한, highway networks 논문에서는 LSTM처럼 gate의 개념을 활용해서 residual을 적용시켰는데 본 논문은 gate가 닫히면(gate에 대한 입력이 0일 때) residual functions를 활용하지않은 highway networks와는 달리 언제나 residual functions을 사용하여 학습한다는 점에서 차이가 존재한다.

<br><br>



## Deep Residual Learning
### 1. Residual Learning
- output H(x)를 F(x) + x로하고 H(x) - x라는 residual function을 찾기위한 학습 방법은 성능을 높이기 위한 방법인지 직관적으로 와닿지 않을 수 있지만, 만약 추가되는 layer들이 identity mapping 되어있다면 모델이 깊어질수록 얕은 모델에 비해 에러가 더 깊어져서는 안 된다. 여기서 identity mapping이란, 이전층과 현재층의 출력이 동일한 값을 가지는 변환이다. 즉, 주어진 입력을 거의 변환시키지 않은채 출력이 이루어져 역전파 과정에서 층을 통과할 때 기울기가 손실되지 않아 기울기 소실문제를 완화하는데 도움을 준다. 입력과 출력의 크기와 차원이 동일한 것을 예로 들 수 있다.
- residual function을 사용할 때 입력과 출력이 동일한 identity mappings이 optimal하다고 가정하면, solvers는 layers들의 가중치를 0으로 만들어 최적의 해인 identity mapping을 만들 것이다. -> x = H(x)가 되어야하니까 H(x) = F(x) + x일 때, F(x)가 0이 되어서 x = H(x)가 됨.
- 실제로 identity mapping이 최적의 해라는 보장이 없지만 완전히 새로운 함수(출력값)를 찾는 것보다는 효과적일 것이고 결과적으로 residual function을 학습하는 방법이 성능을 높이게 됐다.

### 2. Identity Mapping by Shortcuts
<div align="center">
  <p>
  <img width="186" alt="image" src="https://github.com/Hyeonseung0103/Hyeonseung0103.github.io/assets/97672187/1ff495fe-dfd4-4f75-98ad-955f1e73844c">

  </p>
</div>

- residual function을 사용한 output은 위와 같이 정리할 수 있다. 학습에 사용될 F(x)는 입력 x와 가중치 W로 표현한다.

<div align="center">
  <p>
  <img width="186" alt="image" src="https://github.com/Hyeonseung0103/Hyeonseung0103.github.io/assets/97672187/1ff495fe-dfd4-4f75-98ad-955f1e73844c">

  </p>
</div>

- **Figure 2**의 함수 F(x)를 더 자세히 표현하면 위의 식처럼 표현할 수 있는데 $\sigma$ 는 ReLU를 의미한다(편의상 bias는 표시X). 입력 x와 가중치 W1이 곱해지고 ReLU함수를 통과한 후 가중치 W2와 연산이 수행되어 함수 F(x)가 정의된다.
- 이렇게 입력과 출력의 차원이 같다면 차원의 변환없이 F(x)에 x를 더해 output을 도출할 수 있지만, 만약 출력해야 할 차원이 입력된 차원과 다르다면 projection과 같은 방법으로 차원을 변환시켜 원하는대로 출력의 차원을 변환시킬 수 있다. 식은 아래와 같고, $W_{s}$가 차원을 변환시키기 위한 연산이다.
- F가 중첩되지 않고 사용되면 하나의 linear function과 다르지 않기때문에 Figure 2와 같이 F가 여러번 중첩되어 사용될 때 성능이 더 좋았다.

### 3. Network Architectures
기본 layer와 residual layer를 비교하기 위해 VGG를 기반으로 한 plain(기본. residual X) networks를 만들었다. 대부분의 layer에 3x3 filters를 사용했고, output feature map의 크기를 동일하게 하기 위해 모든 레이어에 동일한 필터수를 사용했다. 또한, 피처맵의 크기가 절반으로 줄어들면 필터를 두배로 해서 층마다의 시간 복잡도를 보존했다. 다운 샘플링을 위한 stride는 2를 사용했고 global average pooling과 1000-way fully-connected layer를 사용했다.

결과적으로, VGG보다 적은 수의 필터와 낮은 복잡도를 가지면서 VGG 19의 18% 밖에 되지 않은 연산속도를 기록했다.

<div align="center">
  <p>
  <img width="400" alt="image" src="https://github.com/Hyeonseung0103/Hyeonseung0103.github.io/assets/97672187/83d8319c-684b-4d9d-809b-0efcb06b1696">

  </p>
</div>

<br>

Residual Network를 사용할 때는 대부분 입출력의 차원의 크기를 동일하게 했지만, 만약 출력 크기의 차원이 입력보다 클 경우 zero padding을 사용하여 차원의 크기를 맞추는 방법과 1x1 convolutional filter를 사용하여 projection 하는 방법을 사용할 수 있다.

### 5. Implementation
- ImageNet 데이터에서 256 ~ 480 사이즈로 이미지를 랜덤하게 리사이징
- 리사이징된 이미지를 224x224 크기로 자르고 수평 변환을 수행(RGB 값에서 평균값을 뺀 정규화 수행)
- 합성곱이 끝나고 활성화 함수를 통과하기 전 batch normalization을 수행
- 가중치 초기화, SGD(256 batch size), learning rate 0.1(에러의 개선 없으면 10으로 나눔), iterations 600,000, weight decay 0.0001, momentum 0.9
- Drop out을 사용X
- 테스트를 진행할 때는 이미지를 리사이징하고, 리사이징된 이미지를 10개의 각각 다른 이미지로 crop하여 이 10개의 이미지의 정확도를 평균내어 성능을 평가

## Experiments
### 1. ImageNet Classification
<div align="center">
  <p>
  <img width="407" alt="image" src="https://github.com/Hyeonseung0103/Hyeonseung0103.github.io/assets/97672187/cf8d18ba-7873-4270-aa17-8aca1a9de113">

  </p>
</div>

<br>

- Plain Networks는 18-layer와 32-layer로 성능을 평가. 그 결과, 더 깊은 레이어를 사용한 네트워크의 성능이 더 좋지않았음
- 반면 Plain Networks에 단지 shorcuts만을 추가한 ResNet은 더 깊은 레이어가 얕은 레이어보다 성능이 좋았고, 수렴 속도 또한 빨랐음
- 층이 깊어질수록 발생하는 기울기 소실로 인한 optimization difficulty에 대해 논쟁중 순전파든, 역전파든 signals이 손실되는 현상은 발생하지 않았음. 이를 통해, 최적화 기법에 따른 낮은 수렴율 등과 같은 다른 요인이 성능에 영향을 미칠 수 있다고 판단

**Identity vs Projection Shortcuts**

<div align="center">
  <p>
  <img width="418" alt="image" src="https://github.com/Hyeonseung0103/Hyeonseung0103.github.io/assets/97672187/b6fb4437-6285-4e03-bc20-16085e66a601">

  </p>
</div>

<br>

shorcuts connection에서 identity mapping을 사용할 것인가 vs projection을 사용할 것인가? 
- option A): shortcuts에 identity mapping을 활용, 차원이 증가하면 zero-padding을 활용한 identity mapping
- option B): shortcuts에 identity mapping을 활용, 차원이 증가하면 projection 활용
- option C): 모든 shortcuts에 projection 활용
- option C가 가장 성능이 좋았지만, 이걸 필수적으로 사용해야할만큼 개선율이 높은 것은 아님. 기본적으로 identity mappidng을 사용할 것을 추천.
- Identity shortcuts은 파라미터수를 증가시키지 않기때문에 위의 오른쪽 그림처럼 차원을 감소시켜 파라미터 수를 줄이고 원하는 연산을 수행후 다시 차원을 원래대로 복구시키는 bottlneck architetecture에 대해서는 identity mapping을 사용할 것을 추천
- 깊이가 깊어졌는데도 성능은 좋아지고 VGG보다 낮은 복잡도와 연산속도를 가졌다.

### 2. CIFAR-10 and Analysis
<div align="center">
  <p>
  <img width="343" alt="image" src="https://github.com/Hyeonseung0103/Hyeonseung0103.github.io/assets/97672187/8510edfa-daed-4d0a-a256-7b5a34d11dc7">

  </p>
</div>

<br>

- 32x32 사이즈의 이미지로 ImageNet에 비해서 훨씬 작은 크기의 이미지가 input로 사용된다.
- 3x3 convolutional layer를 시작으로 6n layers의 크기고 3x3 conv layer를 사용했고, 각 conv layer마다 {32,16,8} 사이즈의 피처맵을 구성했다.
- 6n + 2 만큼의 layers를 가지고 ImageNet과 약간 다르지만 거의 유사한 형태로 CIFAR 데이터셋에 맞게 변환 시켰다.

<br>

<div align="center">
  <p>
  <img width="424" alt="image" src="https://github.com/Hyeonseung0103/Hyeonseung0103.github.io/assets/97672187/f14794ae-3927-4615-9bcd-a2bc87cf43c9">

  </p>
</div>

<br>

- CIFAR 데이터셋에서도 ResNet은 깊이가 깊어질수록 더 적은 에러율을 기록했는데 데이터셋의 크기가 그렇게 크지않기때문에 1202개의 layers를 사용했을 때는 과적합이 발생하여 오히려 110개를 사용했을떄보다 성능이 더 좋지 않았다. layers의 깊이는 데이터셋의 크기를 고려하며 쌓아야한다.




### 3. Object Detection on PASCAL and MS COCO
<div align="center">
  <p>
  <img width="422" alt="image" src="https://github.com/Hyeonseung0103/Hyeonseung0103.github.io/assets/97672187/44d49b19-d922-491c-a63d-9cf8dc27f3d7">

  </p>
</div>

<br>

- Object Detection을 위해 PASCAL VOC 2007과 COCO 2012 데이터셋을 사용했을 때도 ResNet이 VGG보다 더 높은 mAP를 기록했다.

**ResNet은 Classification, Detection, Localization 분야에서 모두 1등을 차지한 획기적인 네트워크였다.**

<br><br>

# 개인적인 생각
- 

<br><br>

# 구현
ResNet을 pytorch로 구현해보자([참고]([https://github.com/pytorch/vision/blob/6db1569c89094cf23f3bc41f79275c45e9fcb3f3/torchvision/models/googlenet.py](https://github.com/pytorch/vision/blob/6db1569c89094cf23f3bc41f79275c45e9fcb3f3/torchvision/models/resnet.py)https://github.com/pytorch/vision/blob/6db1569c89094cf23f3bc41f79275c45e9fcb3f3/torchvision/models/resnet.py).

```python

```


```python


```

# 이미지 출처
- [Deep Residual Learning for Image Recognition Paper](https://arxiv.org/pdf/1512.03385v1.pdf)
