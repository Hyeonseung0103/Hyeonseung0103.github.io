---
layout: single
title: "VGG(VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION)논문 요약"
toc: true
toc_sticky: true
category: CNN
---

# Abstract
대규모 이미지 인식에서 Convolutional Network의 깊이와 정확도에 대해 연구했다. 상대적으로 작은 3x3 합성곱 필터를 사용하여 층을 깊게 만들었고, 16 - 19개의 층을 쌓았을 때의 모델이 기존에 연구되었던 
모델들의 성능보다 더 좋은 성능을 기록했다. ImageNet Challenge 2014에서 localisation 부문 1등, classification 부문 2등을 차지했다. 본 연구에서 사용된 모델은 다른 데이터셋에서도 좋은 일반화 능력을 보였고, CV 분야에
도움이 되고자 가장 좋은 ConvNet 모델을 공개한다.



<br><br>

# Details

## 도입부
- ConvNet이 활발하게 사용되면서 AlexNet의 논문과 같이 성능을 높이려는 여러가지 시도들이 존재
- 해당 논문에서는 네트워크의 깊이를 늘리는 것에 초점을 맞췄고, 깊이를 늘리는 대신 작은 3 x 3 convolution filter를 사용
- 결과적으로 기존 모델들보다 성능이 좋은 모델을 얻었고, 본 논문에서는 두 가지 모델 소개

<br><br>

## 모델 구조와 분류
### 1. Architecture
- 합성곱층의 깊이에 따라 성능이 달라지는 것을 확인하기 위해 기본적인 구조는 Ciresan의 2011년 논문과 Krizhevsky의 2012년 논문(AlexNet)을 참고
- 224 x 224 크기의 RGB 이미지를 입력받고, 원본 픽셀값에서 평균을 뺀 전처리 이외의 전처리는 수행하지 않음
- 3 x 3 필터를 사용하고 1 x 1 필터를 사용하기도 함
- 합성곱층의 stride는 1로 고정, 특정 합성곱층 뒤에는 max pooling(2x2, stride 2)층 추가
- Fully Connected 계층에서는 첫번째와 두번째 계층에서 4096개의 채널, 마지막 층에서는 1000개로 분류 진행
- 모든 은닉계층에서 ReLU 사용
- Local Response Normalization은 하나의 네트워크에서만 사용. 오히려 연산량과 메모리 소비량을 증가시키는 기법

<br><br>
**3 x 3 filter**

저자의 경우 이전 모델들이 11x11 혹은 7x7 필터를 사용한 것에 비해 3x3이라는 작은 필터를 사용했다. 3x3을 두겹으로 사용하면 5x5의 효과를, 세겹으로 사용하면 7x7의 효과를 낼 수 있다. 예를 들어 7x7이미지가 있을 때 5x5 필터를
사용하면, 

<br><br>

$$\frac{7-5 + 2 \times 0}{1} + 1 = 3$$

<br><br>

3x3의 결과를 얻을 수 있고 3x3 필터를 사용하면,

<br><br>

$$\frac{7-3 + 2 \times 0}{1} + 1 = 5$$

$$\frac{5-3 + 2 \times 0}{1} + 1 = 3$$

<br><br>
5x5 -> 3x3의 결과를 얻을 수 있다.

그렇다면, 결과적으로 같은 receptive field 효과를 가진다면 굳이 5x5 필터를 한번 사용하지 않고 번거롭게 3x3 필터를 두번 사용하는 이유는 무엇일까? 예를 들어, 채널의 수를 C, 3x3 필터를 2번 사용한다고 가정해보자.
그렇다면 이 층에서의 파라미터 수는 3x3x2xC^2이 될 것이고 만약, 5x5 필터를 한번 사용한다면 이 층에서의 파라미터 수는 5x5xC^2이 될 것이다(C가 제곱인 이유는 input과 output의 채널수를 동일하다고 가정했기때문. 편향은 편의상 제외). 결과적으로, 같은 receptive field 효과를 가지더라도 3x3 필터를 여러번 사용했을때
연산량이 훨씬 줄어들기때문에 3x3 필터를 여러겹 사용하는 것이 더 효과적인 방법이 된다. 또한, ReLU 함수를 여러층에서 통과하게됨으로써 비선형성이 증가해 모델의 학습에 더 도움을 준다.

**1 x 1 filter**

<br><br>

### 2. Configuration

<div align="center">
  <p>
  <img width="412" alt="image" src="https://github.com/Hyeonseung0103/Hyeonseung0103.github.io/assets/97672187/63090975-11b0-42b4-9239-2ea2d97c011c">
  <br>  
    
  출처 [VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION PAPER](https://arxiv.org/pdf/1409.1556v6.pdf)
  </p>
</div>

<br><br>

위의 표는 합성곱층의 깊이를 달리해서 시도한 여러개의 네트워크들이다. A 네트워크는 8개의 합성곱층과 3개의 FC층, E는 16개의 합성곱층과 3개의 FC층으로 이루어져있다. 합성곱층의 깊이만 달리하고 각 층에서의 채널수는 모두 동일하다.
합성곱층의 채널의 갯수는 max pooling이후 2의 제곱으로 증가한다. 각 네트워크마다 이전 네트워크에 비해 추가된 부분은 볼드로 표시했다. 예를 들어 A의 첫번째 합성곱층에는 LRN을 수행하지 않았는데 A-LRN에서는 LRN을 수행했기때문에
볼드로 표시했다.

또한, 아래 표는 각 네트워크별로 사용된 파라미터의 갯수를 나타낸 것이고 3x3 필터를 사용했기때문에 깊이가 깊어진 것에 비해서 사용된 파라미터의 수가 크게 증가하지 않았다는 것을 확인할 수 있다.
<br><br>

<div align="center">
  <p>
  <img width="500" alt="image" src="https://github.com/Hyeonseung0103/Hyeonseung0103.github.io/assets/97672187/78bef296-cfcf-4134-8bde-cf1cc1361608">

  <br>  
    
  출처 [VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION PAPER](https://arxiv.org/pdf/1409.1556v6.pdf)
  </p>
</div>

<br><br>



# 개인적인 생각
-

<br><br>

# 구현

```python
        
        
```

